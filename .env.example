# Ollama Configuration
OLLAMA_URL=http://localhost:11434
OLLAMA_MODEL=llama3:8b
# Note: Any multilingual Open Weight Model will work

# Google Custom Search API (Optional)
GOOGLE_API_KEY=your_google_api_key_here
GOOGLE_SEARCH_ENGINE_ID=your_search_engine_id_here

# ChromaDB Configuration
USE_CHROMADB=true
CHROMA_DB_URL=http://localhost:8000
CHROMA_COLLECTION_NAME=japanese_tutor_knowledge
EMBEDDING_MODEL=all-MiniLM-L6-v2
MAX_CHUNK_SIZE=800
CHUNK_OVERLAP=100

# Server Configuration
PORT=3000
NODE_ENV=development